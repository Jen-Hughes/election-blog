---
title: Blog 7
author: Jen Hughes
date: '2022-10-25'
slug: []
categories: []
tags: []
---



<p>This week we looked at shocks and unexpected events in elections. Shocks are inherently difficult to operationalize and incorporate into models because their nature is that they produce one off events with no clear data to train a model on. The literature looking at shocks has produced an inconclusive lack of consensus. Some studies show even large shocks don’t produce lasting impacts on voter opinion. Others show that even shocks unrelated to politics such as Shark attacks or natural disasters can impact voter behavior (Achen and Bartels). Because shocks are inherently unpredictable, they are difficult to account for in models.</p>
<p>Perhaps the biggest shock in this election cycle was the overturning of Roe v. Wade. The leaked decision and subsequent ruling shook the nation and dominated the election cycle coverage throughout the summer. The Dobbs decision has been a major focus of Democratic campaigns throughout this midterm cycle and Democrats have spent millions of dollars on ads centering this issue. However, the actual impact of abortion on voter behavior remains unclear. To examine shocks during the 2022 election cycle, I performed a Newspaper scrape of the New York Times over the last year to look more closely at the overturning of Roe v. Wade.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" />
I first recreated the NYT scrape from our class discussion section which searched for the keyword “Dobbs”. Initially I was surprised to see that the spike from the actual decision was so much larger than the leaked decision. However, upon further reflection, I reasoned that teh leak gave outlets a month to pre write stories about the eventual overturn which helps explain the drastic difference.</p>
<p>Stemming from our discussion, I was curious about whether or not the large spike in Dobbs articles spurred a broader and more durable conversation about abortion more generally. I ran a newspaper scrape for the key term “abortion” over the last year. If we compare the hits for Dobbs against the hits for abortion, we do see that abortion remained in the conversation for a longer time and at a greater quantity than the term “Dobbs”. However, we still see a significant drop off in mentioned suggesting the lack of durability in a shock like the overturning of Roe v. Wade.</p>
<p>This analysis is also very interesting because it highlights some of the issues with this methodology. Theoretically, searching for abortion vs Dobbs should elicit similar results. I’m attempting to measure the same shock with both terms. But as we see, the results and trends show significant variation based on which term you search for. This comparasion shows that we should be sceptical about how well this scrape can measure the salience of a given shock.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>I then mapped the generic ballot support for each party with markers for the leak and release of the Dobbs Decision. We see that support for both parties increased following the leak of the decision then promptly decreased for both. We see the parties diverge with the release of the final decision where Democrats see an increase in support and Republicans see a decrease. However, the scale of this graph is very small and the changes are difficult to differentiate from general noise.</p>
<p>Model Update:</p>
<pre class="r"><code>#final_data_aggregate &lt;- final_data %&gt;%
#  filter(year != 2022) %&gt;%
#  group_by(year, st_cd_fips) %&gt;%
 # mutate(DEM = as.numeric(DEM), 
   #      REP = as.numeric(REP)) %&gt;%
#  mutate(avg_support_dem = mean(DEM), 
 #        avg_support_rep = mean(REP)) %&gt;%
 # rename_(&quot;DemVotesMajorPercentorig&quot; = &quot;DemVotesMajorPercent&quot;) %&gt;%
 # rename_(&quot;DemVotesMajorPercent&quot; = &quot;DemVotesMajorPct&quot;)</code></pre>
<p>National Model</p>
<pre><code>## 
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                       dem_votes_major_percent  
## -----------------------------------------------
## incumbency                     0.082           
##                               (0.414)          
##                                                
## avg_rating                   -2.649***         
##                               (0.102)          
##                                                
## turnout                      0.125***          
##                               (0.018)          
##                                                
## Constant                     54.561***         
##                               (1.018)          
##                                                
## -----------------------------------------------
## Observations                    214            
## R2                             0.778           
## Adjusted R2                    0.775           
## Residual Std. Error      2.611 (df = 210)      
## F Statistic          245.590*** (df = 3; 210)  
## ===============================================
## Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<pre><code>##        fit      lwr      upr
## 1 47.32147 42.15702 52.48591</code></pre>
<p>I altered my national model to included turnout as a predictive variable. My updated national model now predicts that Democrats will win 42.15% of two party vote share with a confidence interval of 47.3 % - 52.5%.</p>
<p>As I look toward finalizing my prediction model ahead of our final prediction, my biggest concern is making sure that the data I’m putting into my model is accurate, robust, and rational. I don’t doubt that over the course of the last 8 weeks working with this data I inevitably cleaned or joined something wrong and either eliminated good data or introduced data in an illogical way. As I construct my final model I plan to take a meticulous look through each step of the code I have to make sure things are being incorporated correctly. I also need to pull updated data for things like generic ballot polling to make sure that I am using the most up to date data possible in my final prediction because right now many of the data sets stop in December or are missing expert preidcts for certain districts etc. Now that I’ve finalized variables to include, I also want to make sure I’m modeling on the largest dataset available.</p>
