---
title: Blog Post 3 - Polling
author: R package build
date: '2022-09-27'
slug: []
categories: []
tags: []
---

Using Polling to Inform Election Forecasts

Last week, I built a model for the 2022 midterm elections based on the historical relationship between change in Real Disposable Income and election outcome (either Popular Vote Share or Seat Share). While that model was far from perfect and exhibited a great degree of uncertainty, by limiting the data to midterm yebuiars only, I was able to raise the r-squared value to 0.47 indicating that change in RDI from Q8-Q7 in an election year has considerable predictive power. But of course, that model left much to be desired suggesting that other predictive variables should be considered to garner more accurate predictions. One of the potential added variables is polling data. 

Incorporating Polls - 538 vs. The Economist

Similar to the wide array of variables and subsets considered last week when narrowing down an economic variable to model based off of, there is no single way to incorporate polling data into our prediction models. For example, both 538 and The Economist base their models on polling data but the exact methods for how they incorporate polls vary. 

538 produces three different models for each prediction — Lite, Classic, and Deluxe. However, each of these models uses polls in slightly different ways. The Lite model is a “polls-only” assessment of the election.  In practice, the data is of course a bit more complicated than that with the addition of the CANTOR system to fill in polling gaps, but in essence lite models the relationship between polling and outcome.  The Classic version again uses polling but also adds in terms for “the fundamentals” many of which we have already discussed in this blog, like Incumbency and the economy. Silvers doesn’t go into detail about each and every term but notes that “incumbency, past voting history in the state or district, fundraising and the generic ballot” are the most important factors and as such they are weighted to a greater degree than other variables (Silvers 2022). Finally, the deluxe model adds in ratings from elections experts who take a more subjective and qualitative look at predicting individual races.

The Economist Similarly uses a combination of Polling data and Fundamentals to generate their predictions. The Economist cites the generic-ballot as “the single best indicator” of election outcomes in Congressional races. This is reflected in their model which really centers on the generic ballot and builds out from there to incorporate different variables considered in “the fundamentals.” With the generic ballot base, The Economist then uses individual polls to refine and “nudge” their model to be more accurate (Morris 2020). The Economists model also seems to weight polls conducted closer to the election day more heavily.  

I generally find The Economist’s methodology to be more compelling than 538’s.  The Economist seemingly places less value on individual polls and extrapolating (like 538’s CANTOR system).  I’m somewhat skeptical about the assertion that what's true in one district's individual polls can easily be transferred to similar districts.  This is both because the districts where data is readily available are inherently confounded by the fact that they likely either house large universities (who conduct polls) or are particularly competitive. 


```{r, include = FALSE, message = FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(readr)
library(stargazer)
library(blogdown)
```

```{r, , eval = TRUE, echo = FALSE, warning = FALSE, message= FALSE, Include = FALSE}
poll_df <- read_csv("polls_df.csv")
popvote_df <- read_csv('house_popvote_seats.csv')
popvote <- popvote_df %>%
  select('year', 'winner_party', 'H_incumbent_party', 'H_incumbent_party_majorvote_pct','D_majorvote_pct', 'R_majorvote_pct')

RDI <- read_csv('RDI_quarterly.csv')
  
RDI <- RDI %>%
  select('year', 'quarter_cycle', 'DSPIC_change_pct') %>% 
  filter(year == 1982 | year == 1986 | year == 1982 | year == 1986 | year == 1990 | year == 1994 | year == 1994 | year == 1998 | year == 2002 | year == 2006 | year == 2010 | year == 2014 | year == 2018 | year == 2022) %>%  
  filter(quarter_cycle == 8) 
  
pollsRDI <- popvote_df %>% 
    full_join(poll_df %>% 
                  filter(bmonth >= 9) %>% 
                  group_by(year, party) %>% 
                  summarise(avg_support=mean(support))) %>% 
    left_join(RDI)
pollsRDI <- pollsRDI %>%
  drop_na()

```

Below is a model based on only percent change in RDI from Q7 to Q8.  As seen last week, the model paradoxically suggests that an increase in RDI leads to a decrease in Democratic support.  This is slightly different than the model buikt last week which looked at the incumbent party. This model instead looks at Democrats only. Modeling in this way makes sense if we believe that Democrats and Republicans are impacted by different variables differently regardless of who is in power. For all models below, I have chosen to look exclusively at midterm election years as the dynamics aty play in an election year are funsamentally differnt than during presidential election years. 

```{r,eval = TRUE, echo = FALSE, warning = FALSE, message= FALSE, Include = FALSE}
##fundamentals model
demdata <- pollsRDI[pollsRDI$party == 'D',]
#dat_R <- pollsRDI[pollsRDI$party == 'R',]
mod_RDI_D <- lm(D_majorvote_pct ~ DSPIC_change_pct, data = demdata)
#mod_RDI_R <- lm(R_majorvote_pct ~ DSPIC_change_pct, data = dat_R)
stargazer(mod_RDI_D, type = 'text')
#stargazer(mod_RDI_R, type = 'text')
```

I next build a model based on polling only.  This shows us that a 1.1 point increase in generic ballot polling translates to a 1 percent increase in actual voteshare. It's interesting that this relationship isn't 1-1 given that in an ideal scenario polling would align perfectly with results. Also unlike the RDI model, here we see that polling is considered significant.

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message= FALSE, Include = FALSE}
##adjusted polls-only model
mod_polling_D <- lm(D_majorvote_pct ~ avg_support, data = demdata)
#mod_polling_R <- lm(R_majorvote_pct ~ avg_support, data = dat_R)
stargazer(mod_polling_D, type = 'text')
#stargazer(mod_polling_R, type = 'text')
```

The final model combines polling and change in RDI to predict Democratic voteshare.  With an R-sq of 0.88, this is a notable improvement on any of the other models produced so far. Furthermore, both polling and RDI appear to be significant in the model. 

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message= FALSE, Include = FALSE}
## adjusted polls + fundamentals model
mod_pollRDI_D <- lm(D_majorvote_pct ~ avg_support + DSPIC_change_pct, data = demdata)
#mod_pollRDI_R <- lm(R_majorvote_pct ~ avg_support + DSPIC_change_pct, data = dat_R)
stargazer(mod_pollRDI_D, type = 'text')
#stargazer(mod_pollRDI_R, type = 'text')
```


```{r,eval = TRUE, echo = FALSE, warning = FALSE, message= FALSE, Include = FALSE}
D2022 <- data.frame(DSPIC_change_pct = c(-2.00319494), avg_support = 45.1)
#R2022 <- data.frame(DSPIC_change_pct = c(-2.00319494), avg_support = 43.8)

predict(mod_pollRDI_D, newdata = D2022)
#predict(mod_pollRDI_R, newdata = R2022)
```

The combined model now predicts that Democrats will win 55.6% of the two party vote share in the upcoming midterm elections. I believe this is an improvement on the "economy-only" model done last week. 
